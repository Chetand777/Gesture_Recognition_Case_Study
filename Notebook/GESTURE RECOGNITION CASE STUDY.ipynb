{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1879322",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "### As a data scientist at a home electronics company which manufactures state of the art smart televisions. We want to develop a cool feature in the smart-TV that can recognise five different gestures performed by the user which will help users control the TV without using a remote. The training data consists of a few hundred videos categorized into one of the five classes. Each video (typically 2-3 seconds long) is divided into a sequence of 30 frames (images). These videos have been recorded by various people performing one of the five gestures in front of a webcam - similar to what the smart TV will use. \n",
    "\n",
    "### •\tThumbs up\t\t:  Increase the volume.\n",
    "### •\tThumbs down\t\t: Decrease the volume.\n",
    "### •\tLeft swipe\t\t: 'Jump' backwards 10 seconds.\n",
    "### •\tRight swipe\t\t: 'Jump' forward 10 seconds. \n",
    "### •\tStop\t\t\t: Pause the movie. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "71345669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import abc\n",
    "from abc import abstractmethod, ABCMeta\n",
    "from sys import getsizeof\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "import keras\n",
    "from keras import backend as k\n",
    "import tensorflow as tf\n",
    "\n",
    "# Setting the seed for python random module, numpy and tf for reproducibility and debugging purpose\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "np.random.seed(30)\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16522f2e",
   "metadata": {},
   "source": [
    "### The required libraries are imported. Same seed is provided to python random module, numpy and tensorflow for generating same sequence of random numbers every time the code is executed. Without seed code produces different results each time when it is run. The seed makes the experiment deterministics. The abstract method is used to define common interface for the group of related classes. It is important when multiple classes are adhered to common set of methods or properties. The libraries imread and resize are used for preprocessing of images such as reading, processing and transformation (resizing, rotating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "0b67629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing other libraries for model building purpose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, GRU, TimeDistributed, BatchNormalization, Activation, Dropout\n",
    "from keras.layers import Conv2D, Conv3D, MaxPooling2D, MaxPooling3D\n",
    "from keras.layers import LSTM\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a72d30",
   "metadata": {},
   "source": [
    "### For model building purpose we imported above libraries. The sequential model is used for model building layer by layer. For defining the NN architecture different layers are imported. Optimizers are used to control the weights of model thereby affecting the learning process. The call back list is applied at different stages of training to save the model after every epoch, to reduce the LR and stop training early when evaluation metric has stopped improving. The open source computer vision library is used for image processing and color space conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "e1d3c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets initialize the path where project data is saved\n",
    "desktop_path = os.path.join(os.path.join(os.path.expanduser('~')), 'Desktop')\n",
    "project_folder = os.path.join(desktop_path, 'Gesture Recognition Case Study', 'Data', 'Project_data')\n",
    "\n",
    "class ModelBuilder(metaclass=ABCMeta):\n",
    "    def initializepath(self, project_folder):\n",
    "        \n",
    "        self.train_doc = np.random.permutation(open(os.path.join(project_folder, 'train.csv')).readlines()) # List of training data csv\n",
    "        self.val_doc = np.random.permutation(open(os.path.join(project_folder, 'val.csv')).readlines()) # List of val data csv\n",
    "        \n",
    "        self.train_path = os.path.join(project_folder, 'train')    # Path to training images folder\n",
    "        self.val_path = os.path.join(project_folder, 'val')        # Path to val images folder\n",
    "        \n",
    "        self.num_train_seq = len(self.train_doc)  # Number of data seq present in train doc\n",
    "        self.num_val_seq = len(self.val_doc) # Number of data seq present in val doc\n",
    "    \n",
    "    # Lets initialize the image properties \n",
    "    def initialize_img_prop(self, img_width=100, img_height=100):\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.channels = 3  # The attribute channels with value 3 represents color channels\n",
    "        self.classes = 5  # The attribute classes represents the number of classes used in the classification model\n",
    "        self.total_frames = 30  # The attribute shows the total no of frames/time steps used by the model to process seq of images/video\n",
    "    \n",
    "    # Now lets initialize the hyperparameters to control the learning process \n",
    "    def initializehyperparm(self, sample_frames=30, batch_size=20, no_of_epochs=20):\n",
    "        self.sample_frames = sample_frames  # The attribute sample_frames defines the seq of images required to produce video data\n",
    "        self.batch_size = batch_size  # The attribute defines batch size that should be provided during the training of the model\n",
    "        self.no_of_epochs = no_of_epochs  # The no of iterations or the no of times the entire data is passed through NN for training\n",
    "        \n",
    "        \n",
    "        \n",
    "# Lets define a method that generates data for training of NN\n",
    "    def generator(self, source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0, self.total_frames-1, self.sample_frames)).astype(int)\n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        while True:\n",
    "            shuffled_data = np.random.permutation(folder_list)\n",
    "            total_batches = len(shuffled_data) // batch_size\n",
    "            for batch in range(total_batches):\n",
    "                batch_data, batch_label = self.one_batch_data(source_path, shuffled_data, \n",
    "                                                        batch_size, batch,\n",
    "                                                        img_idx, augment)\n",
    "                yield batch_data, batch_label\n",
    "                \n",
    "                \n",
    "            remaining_batches = len(shuffled_data) % batch_size\n",
    "            if remaining_batches != 0:\n",
    "                batch_data, batch_label = self.one_batch_data(source_path, shuffled_data,   \n",
    "                                                          total_batches, batch_size, img_idx, augment, remaining_batches)\n",
    "                yield batch_data, batch_label\n",
    "            \n",
    "            \n",
    "            \n",
    "# Lets generate the data for one batch\n",
    "    def one_batch_data(self, source_path, shuffled_data, batch, batch_size, img_idx, augment, remaining_batches=0):\n",
    "        seq_len = remaining_batches if remaining_batches else self.batch_size\n",
    "        batch_data = np.zeros((seq_len, len(img_idx), self.img_height, self.img_width, self.channels))\n",
    "        batch_label = np.zeros((seq_len, self.classes))\n",
    "\n",
    "        if (augment):\n",
    "            batch_data_aug = np.zeros((seq_len, len(img_idx), self.img_height, self.img_width, self.channels))\n",
    "\n",
    "        for folder in range(seq_len):\n",
    "            \n",
    "            imgs = os.listdir(source_path + '/' + shuffled_data[folder + (batch*batch_size)].split(';')[0])\n",
    "            \n",
    "            for idx, item in enumerate(img_idx):\n",
    "                    \n",
    "                img_read = imread(source_path + '/' + shuffled_data[folder + (batch*batch_size)].strip().split(';')[0]\n",
    "                                         + '/' + imgs[item]).astype(np.float32)\n",
    "                img_resize = resize(img_read, (self.img_height, self.img_width, 3))\n",
    "\n",
    "                batch_data[folder, idx, :, :, 0] = (img_resize[:, :, 0]) / 255\n",
    "                batch_data[folder, idx, :, :, 1] = (img_resize[:, :, 1]) / 255\n",
    "                batch_data[folder, idx, :, :, 2] = (img_resize[:, :, 2]) / 255\n",
    "\n",
    "                if (augment):\n",
    "                    transformed_img = cv2.warpAffine(img_read, np.float32([[1, 0, np.random.randint(-30, 30)],\n",
    "                                                                          [0, 1, np.random.randint(-30, 30)]]),\n",
    "                                                    (img_read.shape[1], img_read.shape[0]))\n",
    "                    gray_scale = cv2.cvtColor(transformed_img, cv2.COLOR_BGR2GRAY)\n",
    "                    x0, y0 = np.argwhere(gray_scale > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray_scale > 0).max(axis=0)\n",
    "                    cropped_img = transformed_img[x0:x1, y0:y1, :]\n",
    "                    img_resize = resize(cropped_img, (self.img_height, self.img_width, 3))\n",
    "\n",
    "                    batch_data_aug[folder, idx, :, :, 0] = (img_resize[:, :, 0]) / 255\n",
    "                    batch_data_aug[folder, idx, :, :, 1] = (img_resize[:, :, 1]) / 255\n",
    "                    batch_data_aug[folder, idx, :, :, 2] = (img_resize[:, :, 2]) / 255\n",
    "                    \n",
    "                               \n",
    "            batch_label[folder, int(shuffled_data[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "    \n",
    "        if (augment):\n",
    "            batch_data = np.concatenate([batch_data, batch_data_aug])\n",
    "            batch_label = np.concatenate([batch_label, batch_label])\n",
    "\n",
    "        return batch_data, batch_label                                            \n",
    "                                                  \n",
    "        \n",
    "        \n",
    "# Lets define a method that trains NN using generator to load and augment data\n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_data_generator = self.generator(self.train_path, self.train_doc, augment=augment_data)                                            \n",
    "        val_data_generator = self.generator(self.val_path, self.val_doc)         \n",
    "         \n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ', '').replace(':', '_') + '/'                                         \n",
    "                                                     \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)                                      \n",
    "                                                     \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'                                            \n",
    "                                                     \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False,\n",
    "                                     mode='auto')                                            \n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=4, factor=0.2)                                            \n",
    "        earlystop = EarlyStopping(monitor='val_loss', verbose=1, patience=10, min_delta=0)                                            \n",
    "        callback_list = [checkpoint, LR, earlystop]\n",
    "                                                     \n",
    "        if (self.num_train_seq % self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_seq / self.batch_size)                                      \n",
    "        else:                                     \n",
    "            steps_per_epoch = (self.num_train_seq // self.batch_size) + 1                                      \n",
    "                                                     \n",
    "        if (self.num_val_seq % self.batch_size) == 0:\n",
    "            val_steps = int(self.num_val_seq / self.batch_size)                                      \n",
    "        else:                                     \n",
    "            val_steps = (self.num_val_seq // self.batch_size) + 1                                            \n",
    "                                                     \n",
    "        history = model.fit_generator(train_data_generator, steps_per_epoch=steps_per_epoch, epochs=self.no_of_epochs, verbose=1, \n",
    "                            callbacks=callback_list, validation_data=val_data_generator, \n",
    "                            validation_steps=val_steps, class_weight=None, workers=1, initial_epoch=0)                                            \n",
    "                                                     \n",
    "        return history                                            \n",
    "                                                     \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass                                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6576f07",
   "metadata": {},
   "source": [
    "### 1) In first block of code we defined 3 methods initializepath, image prop and hyperparameters. The first method initializes path for training and validation datasets. Read the csv files containing sequences of data and sets path accordingly. The second method initializes the img prop such as height, width, color channels, classes and total no of frames used by the model. The 3rd method initializes the hyperparameters to control the training of model such as sample frames, batch size and no of epochs.\n",
    "### 2) Second block of code uses the method generator to create data for single batch using one batch data method. The generator creates the list of indices of frames to be sampled, defines the size of each batch, shuffles the data and calculates the total no of batches formed using length of data and eac batch size. The one batch data method iterates over total batches formed and yields data for single batch and corrosponding labels. There might be remaining data that doesnt fit fully into a batch. If there are remaining batches, one batch data is again called with adjusted parameters and yeilds the data and labels for that batches. \n",
    "### 3) In 3rd block we set the length of data sequences in a batch either to batch size or to remaining batches if present. The batch data and label are arrays to store preprocessed img data and labels. The code then enters the loop that iterates over each sequence in batch and returns the list of imgs from shuffled data. Each img in img idx is then read and resized. There pixel values are normalised between 0 and 1. If data augmentation is specified, we provide additional data with  diversity for training of model. It applies affine transformation to img to slide the img horizontally and vertically. The color scale of img is also changed to gray. The nonzero coordinates of gray scale img are used to outline the imp feature. The img is then cropped using coordinates. The resized img is stored in batch data augmentation with normalization. For each sequence in batch it extracts the label from shuffled data and make corrosponding entry to 1. If augmentation is true, the augmented data and batch data is merged.\n",
    "### 4) The next block is responsible for training of NN using data generators. Using generator method train and val sets are generated. The directory model name is created to save the trained models and related onfo. It creates timestamp to make each run unique. A filepath is then created to format the saved model name. It takes a placeholder for epoch, train loss, train acc, val loss, val acc. A callback list is used to save the models with best val loss during training. It monitors the val loss and saves entire model after every epoch. The model is then trained using fit generator and return the history of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "ff916075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build a sample model architecture with different layers\n",
    "class Conv3DModel(ModelBuilder):\n",
    "    def define_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,(3,3,3), padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.25)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a5206",
   "metadata": {},
   "source": [
    "###  The class Conv3DModel is a child class which inherits the properties from parent class ModelBuilder. A sequential model is created and layers are added to the model one by one. Zero padding is added to input therefore the shape of output is same as input. A convolutional filter layer is added with 16,32,64,128 filters each of size (3,3,3). A Relu activation layer is then added to bring some nonlinearity in model. A batch normalization layer normalizes the output from prev layer thus speeding up the process and giving stability to model. A maxpooling3D layer is added to reduce the dimensions of input feature. A flatten layer converts the 3D output to 1D array preparing it for fully connected layer. A dense layer with 64 and 128 nuerons with activation function relu is added as a fully connected layer. A dropout layer with rate 05 and 0.25 is then added to reduce the overfitting. At last a dense layer with 5 output classes and softmax activation function is added to produce o/p probabilities for each class. The model is then compiled using adam optimizer to bring down categorical crossentropy loss function and increase the accuracy meric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "1c232fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_112\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_480 (Conv3D)         (None, 30, 160, 160, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_480 (Activation  (None, 30, 160, 160, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_746 (B  (None, 30, 160, 160, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_384 (MaxPool  (None, 30, 80, 80, 16)    0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_481 (Conv3D)         (None, 30, 80, 80, 32)    4128      \n",
      "                                                                 \n",
      " activation_481 (Activation  (None, 30, 80, 80, 32)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_747 (B  (None, 30, 80, 80, 32)    128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_385 (MaxPool  (None, 30, 40, 40, 32)    0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_482 (Conv3D)         (None, 30, 40, 40, 64)    16448     \n",
      "                                                                 \n",
      " activation_482 (Activation  (None, 30, 40, 40, 64)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_748 (B  (None, 30, 40, 40, 64)    256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_386 (MaxPool  (None, 30, 20, 20, 64)    0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_483 (Conv3D)         (None, 30, 20, 20, 128)   65664     \n",
      "                                                                 \n",
      " activation_483 (Activation  (None, 30, 20, 20, 128)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_749 (B  (None, 30, 20, 20, 128)   512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_387 (MaxPool  (None, 30, 10, 10, 128)   0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_112 (Flatten)       (None, 384000)            0         \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 128)               49152128  \n",
      "                                                                 \n",
      " batch_normalization_750 (B  (None, 128)               512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_272 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_751 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_273 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 49249989 (187.87 MB)\n",
      "Trainable params: 49249125 (187.87 MB)\n",
      "Non-trainable params: 864 (3.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model with different parameters\n",
    "sample_Conv_model = Conv3DModel()\n",
    "sample_Conv_model.initializepath(project_folder)\n",
    "sample_Conv_model.initialize_img_prop(img_width = 160, img_height = 160)\n",
    "sample_Conv_model.initializehyperparm(sample_frames = 30, batch_size = 10, no_of_epochs = 1)\n",
    "sample_Conv_model1 = sample_Conv_model.define_model()\n",
    "sample_Conv_model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4958d14",
   "metadata": {},
   "source": [
    "### The conv3D model is set with different parameters. The sample conv model is initialized by calling conv3Dmodel class. The methods defined in parent class model builder are inherited by child class conv3Dmodel to set up the sample conv model. The abstract method define model defines the model architecture and configuration for consistent structure. The summary of model architecture, layer types, output shapes, and the number of parameters are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "da8bd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with image resolution, sample frames to use and batch size\n",
    "# sample_Conv_model.train_model(sample_Conv_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64573029",
   "metadata": {},
   "source": [
    "### The sample conv model is an instance of conv3Dmodel class which is a child class of ModelBuilder class. Here we called train model method defined in ModelBuilder class to train the sample conv model1 which is a NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "8908b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets trade off between these hyperparameters\n",
    "# sample_Conv_model = Conv3DModel()\n",
    "# sample_Conv_model.initializepath(project_folder)\n",
    "# sample_Conv_model.initialize_img_prop(img_width = 100, img_height = 100)\n",
    "# sample_Conv_model.initializehyperparm(sample_frames = 15, batch_size = 30, no_of_epochs = 2)\n",
    "# sample_Conv_model1 = sample_Conv_model.define_model()\n",
    "# print(f'Total Params: {sample_Conv_model1.count_params()}')\n",
    "# sample_Conv_model.train_model(sample_Conv_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "31c15f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets trade off between these hyperparameters\n",
    "# sample_Conv_model = Conv3DModel()\n",
    "# sample_Conv_model.initializepath(project_folder)\n",
    "# sample_Conv_model.initialize_img_prop(img_width = 100, img_height = 100)\n",
    "# sample_Conv_model.initializehyperparm(sample_frames = 30, batch_size = 20, no_of_epochs = 2)\n",
    "# sample_Conv_model1 = sample_Conv_model.define_model()\n",
    "# print(f'Total Params: {sample_Conv_model1.count_params()}')\n",
    "# sample_Conv_model.train_model(sample_Conv_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "1755537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets trade off between these hyperparameters\n",
    "# sample_Conv_model = Conv3DModel()\n",
    "# sample_Conv_model.initializepath(project_folder)\n",
    "# sample_Conv_model.initialize_img_prop(img_width = 160, img_height = 160)\n",
    "# sample_Conv_model.initializehyperparm(sample_frames = 30, batch_size = 15, no_of_epochs = 2)\n",
    "# sample_Conv_model1 = sample_Conv_model.define_model()\n",
    "# print(f'Total Params: {sample_Conv_model1.count_params()}')\n",
    "# sample_Conv_model.train_model(sample_Conv_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "d9af05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets trade off between these hyperparameters\n",
    "# sample_Conv_model = Conv3DModel()\n",
    "# sample_Conv_model.initializepath(project_folder)\n",
    "# sample_Conv_model.initialize_img_prop(img_width = 160, img_height = 160)\n",
    "# sample_Conv_model.initializehyperparm(sample_frames = 16, batch_size = 30, no_of_epochs = 2)\n",
    "# sample_Conv_model1 = sample_Conv_model.define_model()\n",
    "# print(f'Total Params: {sample_Conv_model1.count_params()}')\n",
    "# sample_Conv_model.train_model(sample_Conv_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65faaa4",
   "metadata": {},
   "source": [
    "### From the above experiments we can see that, the image resolution and sample frames in sequence have more impact on training time than batch size. We can take batch size from 15 to 40 and will change the resolution of image from 160,160 to 120,120 based on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e497a7f4",
   "metadata": {},
   "source": [
    "# Model 1: Image Resolution: (160,160), Sample Frames: 20, Batch Size: 40, No of Epochs: 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "40174417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 1 architecture with different layers\n",
    "class Conv3DModel(ModelBuilder):\n",
    "    def define_model(self, filter_size=(3,3,3), dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "56f3c95f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_113\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_484 (Conv3D)         (None, 20, 160, 160, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_484 (Activation  (None, 20, 160, 160, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_752 (B  (None, 20, 160, 160, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_388 (MaxPool  (None, 10, 80, 80, 16)    0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_485 (Conv3D)         (None, 10, 80, 80, 32)    13856     \n",
      "                                                                 \n",
      " activation_485 (Activation  (None, 10, 80, 80, 32)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_753 (B  (None, 10, 80, 80, 32)    128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_389 (MaxPool  (None, 5, 40, 40, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_486 (Conv3D)         (None, 5, 40, 40, 64)     55360     \n",
      "                                                                 \n",
      " activation_486 (Activation  (None, 5, 40, 40, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_754 (B  (None, 5, 40, 40, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_390 (MaxPool  (None, 2, 20, 20, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_487 (Conv3D)         (None, 2, 20, 20, 128)    221312    \n",
      "                                                                 \n",
      " activation_487 (Activation  (None, 2, 20, 20, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_755 (B  (None, 2, 20, 20, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_391 (MaxPool  (None, 1, 10, 10, 128)    0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_113 (Flatten)       (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_323 (Dense)           (None, 64)                819264    \n",
      "                                                                 \n",
      " batch_normalization_756 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_274 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_757 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_275 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1117061 (4.26 MB)\n",
      "Trainable params: 1116325 (4.26 MB)\n",
      "Non-trainable params: 736 (2.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 1 with different parameters\n",
    "Conv_model = Conv3DModel()\n",
    "Conv_model.initializepath(project_folder)\n",
    "Conv_model.initialize_img_prop(img_width = 160, img_height = 160)\n",
    "Conv_model.initializehyperparm(sample_frames = 20, batch_size = 40, no_of_epochs = 15) \n",
    "Conv_model1 = Conv_model.define_model()\n",
    "Conv_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "fe373b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model1.count_params()}')\n",
    "# model1_hist = Conv_model.train_model(Conv_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821d2b8",
   "metadata": {},
   "source": [
    "# Model 2: Image Resolution: (160,160), Sample Frames: 20, Batch Size: 20, No of Epochs: 25\n",
    "## Adding dropout layers to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "507812f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_488 (Conv3D)         (None, 20, 160, 160, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_488 (Activation  (None, 20, 160, 160, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_758 (B  (None, 20, 160, 160, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_392 (MaxPool  (None, 10, 80, 80, 16)    0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_489 (Conv3D)         (None, 10, 80, 80, 32)    13856     \n",
      "                                                                 \n",
      " activation_489 (Activation  (None, 10, 80, 80, 32)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_759 (B  (None, 10, 80, 80, 32)    128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_393 (MaxPool  (None, 5, 40, 40, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_490 (Conv3D)         (None, 5, 40, 40, 64)     55360     \n",
      "                                                                 \n",
      " activation_490 (Activation  (None, 5, 40, 40, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_760 (B  (None, 5, 40, 40, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_394 (MaxPool  (None, 2, 20, 20, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_491 (Conv3D)         (None, 2, 20, 20, 128)    221312    \n",
      "                                                                 \n",
      " activation_491 (Activation  (None, 2, 20, 20, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_761 (B  (None, 2, 20, 20, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_395 (MaxPool  (None, 1, 10, 10, 128)    0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_114 (Flatten)       (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_326 (Dense)           (None, 256)               3277056   \n",
      "                                                                 \n",
      " batch_normalization_762 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_276 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_327 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_763 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_277 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_328 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3638981 (13.88 MB)\n",
      "Trainable params: 3637477 (13.88 MB)\n",
      "Non-trainable params: 1504 (5.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 2 with different parameters\n",
    "Conv_model1 = Conv3DModel()\n",
    "Conv_model1.initializepath(project_folder)\n",
    "Conv_model1.initialize_img_prop(img_width = 160, img_height = 160)\n",
    "Conv_model1.initializehyperparm(sample_frames = 20, batch_size = 20, no_of_epochs = 25) \n",
    "Conv_model2 = Conv_model1.define_model(dens_nuerons=256, dropout=0.5)\n",
    "Conv_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "a40c168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model2.count_params()}')\n",
    "# model2_hist = Conv_model1.train_model(Conv_model2, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0dba79",
   "metadata": {},
   "source": [
    "# Model 3: Image Resolution: (120,120), Sample Frames: 16, Batch Size: 30, No of Epochs: 25\n",
    "## Reduce the filter size to capture less complex features, to reduce model complexity and to lower the memory requiements, learning rate to 0.0002 to reduce overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "c0705a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 3 architecture with reduced LR\n",
    "class Conv3DModel(ModelBuilder):\n",
    "    def define_model(self, filter_size=(3,3,3), dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "9b67a9d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_115\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_492 (Conv3D)         (None, 16, 120, 120, 16   400       \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_492 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_764 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_396 (MaxPool  (None, 8, 60, 60, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_493 (Conv3D)         (None, 8, 60, 60, 32)     4128      \n",
      "                                                                 \n",
      " activation_493 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_765 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_397 (MaxPool  (None, 4, 30, 30, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_494 (Conv3D)         (None, 4, 30, 30, 64)     16448     \n",
      "                                                                 \n",
      " activation_494 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_766 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_398 (MaxPool  (None, 2, 15, 15, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_495 (Conv3D)         (None, 2, 15, 15, 128)    65664     \n",
      "                                                                 \n",
      " activation_495 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_767 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_399 (MaxPool  (None, 1, 7, 7, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_115 (Flatten)       (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 256)               1605888   \n",
      "                                                                 \n",
      " batch_normalization_768 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_278 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_769 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_279 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1762613 (6.72 MB)\n",
      "Trainable params: 1761109 (6.72 MB)\n",
      "Non-trainable params: 1504 (5.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 3 with different parameters\n",
    "Conv_model2 = Conv3DModel()\n",
    "Conv_model2.initializepath(project_folder)\n",
    "Conv_model2.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model2.initializehyperparm(sample_frames = 16, batch_size = 30, no_of_epochs = 25) \n",
    "Conv_model3 = Conv_model2.define_model(filter_size=(2,2,2), dens_nuerons=256, dropout=0.5)\n",
    "Conv_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7e2d98da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model3.count_params()}')\n",
    "# model3_hist = Conv_model2.train_model(Conv_model3, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec44e0",
   "metadata": {},
   "source": [
    "###  We get total params half of the model 2 by reducing filter size. Lets add more layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd0492d",
   "metadata": {},
   "source": [
    "# Model 4: Image Resolution: (120,120), Sample Frames: 16, Batch Size: 20, No of Epochs: 25\n",
    "## Adding more convolutional layers with earlier filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "073702c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 4 architecture with adding more layers\n",
    "class Conv3DModel(ModelBuilder):\n",
    "    def define_model(self, filter_size=(3,3,3), dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())             # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "f9a75cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_496 (Conv3D)         (None, 16, 120, 120, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_496 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_770 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " conv3d_497 (Conv3D)         (None, 16, 120, 120, 16   6928      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_497 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_771 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_400 (MaxPool  (None, 8, 60, 60, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_498 (Conv3D)         (None, 8, 60, 60, 32)     13856     \n",
      "                                                                 \n",
      " activation_498 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_772 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_499 (Conv3D)         (None, 8, 60, 60, 32)     27680     \n",
      "                                                                 \n",
      " activation_499 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_773 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_401 (MaxPool  (None, 4, 30, 30, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_500 (Conv3D)         (None, 4, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_500 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_774 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_501 (Conv3D)         (None, 4, 30, 30, 64)     110656    \n",
      "                                                                 \n",
      " activation_501 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_775 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_402 (MaxPool  (None, 2, 15, 15, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_502 (Conv3D)         (None, 2, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_502 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_776 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_503 (Conv3D)         (None, 2, 15, 15, 128)    442496    \n",
      "                                                                 \n",
      " activation_503 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_777 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_403 (MaxPool  (None, 1, 7, 7, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_116 (Flatten)       (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 256)               1605888   \n",
      "                                                                 \n",
      " batch_normalization_778 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_280 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_779 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_281 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2556533 (9.75 MB)\n",
      "Trainable params: 2554549 (9.74 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 4 with different parameters\n",
    "Conv_model3 = Conv3DModel()\n",
    "Conv_model3.initializepath(project_folder)\n",
    "Conv_model3.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model3.initializehyperparm(sample_frames = 16, batch_size = 20, no_of_epochs = 25) \n",
    "Conv_model4 = Conv_model3.define_model(filter_size=(3,3,3), dens_nuerons=256, dropout=0.5)\n",
    "Conv_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "7a2c0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model4.count_params()}')\n",
    "# model4_hist = Conv_model3.train_model(Conv_model4, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc52d7a",
   "metadata": {},
   "source": [
    "# Model 5: Image Resolution: (120,120), Sample Frames: 16, Batch Size: 20, No of Epochs: 15\n",
    "## Add dropout layers after every convolutional layer to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "b850af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 5 architecture with adding dropout layers\n",
    "class Conv3DModel(ModelBuilder):\n",
    "    def define_model(self, filter_size=(3,3,3), dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())             # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        model.add(Dropout(dropout))                  # Dropout Layer\n",
    "    \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        model.add(Dropout(dropout))                  # Dropout Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        model.add(Dropout(dropout))                  # Dropout Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        model.add(Dropout(dropout))                  # Dropout Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c41f0c53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_117\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_504 (Conv3D)         (None, 16, 120, 120, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_504 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_780 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " conv3d_505 (Conv3D)         (None, 16, 120, 120, 16   6928      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_505 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_781 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_404 (MaxPool  (None, 8, 60, 60, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " dropout_282 (Dropout)       (None, 8, 60, 60, 16)     0         \n",
      "                                                                 \n",
      " conv3d_506 (Conv3D)         (None, 8, 60, 60, 32)     13856     \n",
      "                                                                 \n",
      " activation_506 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_782 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_507 (Conv3D)         (None, 8, 60, 60, 32)     27680     \n",
      "                                                                 \n",
      " activation_507 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_783 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_405 (MaxPool  (None, 4, 30, 30, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " dropout_283 (Dropout)       (None, 4, 30, 30, 32)     0         \n",
      "                                                                 \n",
      " conv3d_508 (Conv3D)         (None, 4, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_508 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_784 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_509 (Conv3D)         (None, 4, 30, 30, 64)     110656    \n",
      "                                                                 \n",
      " activation_509 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_785 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_406 (MaxPool  (None, 2, 15, 15, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " dropout_284 (Dropout)       (None, 2, 15, 15, 64)     0         \n",
      "                                                                 \n",
      " conv3d_510 (Conv3D)         (None, 2, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_510 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_786 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_511 (Conv3D)         (None, 2, 15, 15, 128)    442496    \n",
      "                                                                 \n",
      " activation_511 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_787 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_407 (MaxPool  (None, 1, 7, 7, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " dropout_285 (Dropout)       (None, 1, 7, 7, 128)      0         \n",
      "                                                                 \n",
      " flatten_117 (Flatten)       (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_335 (Dense)           (None, 256)               1605888   \n",
      "                                                                 \n",
      " batch_normalization_788 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_286 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_336 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_789 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_287 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_337 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2556533 (9.75 MB)\n",
      "Trainable params: 2554549 (9.74 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 5 with different parameters\n",
    "Conv_model4 = Conv3DModel()\n",
    "Conv_model4.initializepath(project_folder)\n",
    "Conv_model4.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model4.initializehyperparm(sample_frames = 16, batch_size = 20, no_of_epochs = 15) \n",
    "Conv_model5 = Conv_model4.define_model(filter_size=(3,3,3), dens_nuerons=256, dropout=0.25)\n",
    "Conv_model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "9d5e3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model5.count_params()}')\n",
    "# model5_hist = Conv_model4.train_model(Conv_model5, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3d8c7",
   "metadata": {},
   "source": [
    "### The model doesnt seem to be generalized. Lets try reducing the total params and see the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d41b610",
   "metadata": {},
   "source": [
    "# Model 6: Image Resolution: (100,100), Sample Frames: 16, Batch Size: 20, No of Epochs: 20\n",
    "## Reduce the filter size again to reduce model complexity. Also reduce the no of neurons in dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "f039e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 6 architecture with reduced filter size\n",
    "class Conv3DModel(ModelBuilder):\n",
    "    def define_model(self, dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,(3,3,3), padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "dace136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_512 (Conv3D)         (None, 16, 100, 100, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_512 (Activation  (None, 16, 100, 100, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_790 (B  (None, 16, 100, 100, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_408 (MaxPool  (None, 8, 50, 50, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_513 (Conv3D)         (None, 8, 50, 50, 32)     4128      \n",
      "                                                                 \n",
      " activation_513 (Activation  (None, 8, 50, 50, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_791 (B  (None, 8, 50, 50, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_409 (MaxPool  (None, 4, 25, 25, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_514 (Conv3D)         (None, 4, 25, 25, 64)     16448     \n",
      "                                                                 \n",
      " activation_514 (Activation  (None, 4, 25, 25, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_792 (B  (None, 4, 25, 25, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_410 (MaxPool  (None, 2, 12, 12, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_515 (Conv3D)         (None, 2, 12, 12, 128)    65664     \n",
      "                                                                 \n",
      " activation_515 (Activation  (None, 2, 12, 12, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_793 (B  (None, 2, 12, 12, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_411 (MaxPool  (None, 1, 6, 6, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_118 (Flatten)       (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_338 (Dense)           (None, 128)               589952    \n",
      "                                                                 \n",
      " batch_normalization_794 (B  (None, 128)               512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_288 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_339 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_795 (B  (None, 128)               512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_289 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_340 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 696645 (2.66 MB)\n",
      "Trainable params: 695653 (2.65 MB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 6 with different parameters\n",
    "Conv_model5 = Conv3DModel()\n",
    "Conv_model5.initializepath(project_folder)\n",
    "Conv_model5.initialize_img_prop(img_width = 100, img_height = 100)\n",
    "Conv_model5.initializehyperparm(sample_frames = 16, batch_size = 20, no_of_epochs = 20) \n",
    "Conv_model6 = Conv_model5.define_model(dens_nuerons=128, dropout=0.25)\n",
    "Conv_model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "14de29be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model6.count_params()}')\n",
    "# model5_hist = Conv_model5.train_model(Conv_model6, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95dad5",
   "metadata": {},
   "source": [
    "### After reducing no of params we get the best validation accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd45461",
   "metadata": {},
   "source": [
    "# Model 7: Image Resolution: (120,120), Sample Frames: 16, Batch Size: 20, No of Epochs: 25\n",
    "## Increase the image resolution and no of epoches and reduce the no of neurons in dense layer to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "9f7d8cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 7 architecture with reduced filter size\n",
    "class Conv3DModel(ModelBuilder):\n",
    "    def define_model(self, dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,(3,3,3), padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,(3,3,3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "e3bf41ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_119\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_516 (Conv3D)         (None, 16, 120, 120, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_516 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_796 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_412 (MaxPool  (None, 8, 60, 60, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_517 (Conv3D)         (None, 8, 60, 60, 32)     13856     \n",
      "                                                                 \n",
      " activation_517 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_797 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_413 (MaxPool  (None, 4, 30, 30, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_518 (Conv3D)         (None, 4, 30, 30, 64)     16448     \n",
      "                                                                 \n",
      " activation_518 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_798 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_414 (MaxPool  (None, 2, 15, 15, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_519 (Conv3D)         (None, 2, 15, 15, 128)    65664     \n",
      "                                                                 \n",
      " activation_519 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_799 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_415 (MaxPool  (None, 1, 7, 7, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_119 (Flatten)       (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_341 (Dense)           (None, 64)                401472    \n",
      "                                                                 \n",
      " batch_normalization_800 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_290 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_342 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_801 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_291 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_343 (Dense)           (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504709 (1.93 MB)\n",
      "Trainable params: 503973 (1.92 MB)\n",
      "Non-trainable params: 736 (2.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 7 with different parameters\n",
    "Conv_model6 = Conv3DModel()\n",
    "Conv_model6.initializepath(project_folder)\n",
    "Conv_model6.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model6.initializehyperparm(sample_frames = 16, batch_size = 20, no_of_epochs = 20) \n",
    "Conv_model7 = Conv_model6.define_model(dens_nuerons=64, dropout=0.25)\n",
    "Conv_model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "3384bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model7.count_params()}')\n",
    "# model7_hist = Conv_model6.train_model(Conv_model7, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c74784",
   "metadata": {},
   "source": [
    "# Model 8: Image Resolution: (120,120), Sample Frames: 18, Batch Size: 20, No of Epochs: 25\n",
    "## CNN + LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a3628520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 8 architecture with CNN+LSTM\n",
    "class CNNLSTM(ModelBuilder):\n",
    "    def define_model(self, lstm_cells=64, dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv2D(16,(3,3), padding='same', activation='relu',\n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels))))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2)))) # Convolutional Layer\n",
    "    \n",
    "        model.add(TimeDistributed(Conv2D(32,(3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2)))) # Convolutional Layer\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64,(3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2)))) # Convolutional Layer\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128,(3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2)))) # Convolutional Layer\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(256,(3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2)))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(TimeDistributed(Flatten()))  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))  # LSTM Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "a51488c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_120\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_208 (Time  (None, 18, 120, 120, 16   448       \n",
      " Distributed)                )                                   \n",
      "                                                                 \n",
      " time_distributed_209 (Time  (None, 18, 120, 120, 16   64        \n",
      " Distributed)                )                                   \n",
      "                                                                 \n",
      " time_distributed_210 (Time  (None, 18, 60, 60, 16)    0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_211 (Time  (None, 18, 60, 60, 32)    4640      \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_212 (Time  (None, 18, 60, 60, 32)    128       \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_213 (Time  (None, 18, 30, 30, 32)    0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_214 (Time  (None, 18, 30, 30, 64)    18496     \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_215 (Time  (None, 18, 30, 30, 64)    256       \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_216 (Time  (None, 18, 15, 15, 64)    0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_217 (Time  (None, 18, 15, 15, 128)   73856     \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_218 (Time  (None, 18, 15, 15, 128)   512       \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_219 (Time  (None, 18, 7, 7, 128)     0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_220 (Time  (None, 18, 7, 7, 256)     295168    \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_221 (Time  (None, 18, 7, 7, 256)     1024      \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_222 (Time  (None, 18, 3, 3, 256)     0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_223 (Time  (None, 18, 2304)          0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 128)               1245696   \n",
      "                                                                 \n",
      " dropout_292 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_344 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_293 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_345 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1657445 (6.32 MB)\n",
      "Trainable params: 1656453 (6.32 MB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 8 with different parameters\n",
    "Conv_model7 = CNNLSTM()\n",
    "Conv_model7.initializepath(project_folder)\n",
    "Conv_model7.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model7.initializehyperparm(sample_frames = 18, batch_size = 20, no_of_epochs = 20) \n",
    "Conv_model8 = Conv_model7.define_model(lstm_cells=128, dens_nuerons=128, dropout=0.25)\n",
    "Conv_model8.build((None, 18, 120, 120, 3))\n",
    "Conv_model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "7517b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model8.count_params()}')\n",
    "# model8_hist = Conv_model7.train_model(Conv_model8, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743c6d9f",
   "metadata": {},
   "source": [
    "### There are still cases of overfitting. Lets augment the data with slight rotation and run same set of models again. The time distributed wrapper applies the same layer to each time step of input sequence independently. Therefore we need to apply 2D convolution to each frame of 3D input sequence. Here, the convolutional layer is used for spatial feature extraction and LSTM layer is used for capturing the temporal dependencies in sequence of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345c73e",
   "metadata": {},
   "source": [
    "# Model 9: Image Resolution: (160,160), Sample Frames: 20, Batch Size: 20, No of Epochs: 20 (Data Augmentation)\n",
    "## Similar to model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "83ae24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets apply some data augmentation and check model performance\n",
    "desktop_path = os.path.join(os.path.join(os.path.expanduser('~')), 'Desktop')\n",
    "project_folder = os.path.join(desktop_path, 'Gesture Recognition Case Study', 'Data', 'Project_data')\n",
    "\n",
    "class ModelBuilderMoreAugmentation(metaclass=ABCMeta):\n",
    "    def initializepath(self, project_folder):\n",
    "        \n",
    "        self.train_doc = np.random.permutation(open(os.path.join(project_folder, 'train.csv')).readlines()) # List of training data csv\n",
    "        self.val_doc = np.random.permutation(open(os.path.join(project_folder, 'val.csv')).readlines()) # List of val data csv\n",
    "        \n",
    "        self.train_path = os.path.join(project_folder, 'train')    # Path to training images folder\n",
    "        self.val_path = os.path.join(project_folder, 'val')        # Path to val images folder\n",
    "        \n",
    "        self.num_train_seq = len(self.train_doc)  # Number of data seq present in train doc\n",
    "        self.num_val_seq = len(self.val_doc) # Number of data seq present in val doc\n",
    "    \n",
    "    # Lets initialize the image properties \n",
    "    def initialize_img_prop(self, img_width=100, img_height=100):\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.channels = 3  # The attribute channels with value 3 represents color channels\n",
    "        self.classes = 5  # The attribute classes represents the number of classes used in the classification model\n",
    "        self.total_frames = 30  # The attribute shows the total no of frames/time steps used by the model to process seq of images/video\n",
    "    \n",
    "    # Now lets initialize the hyperparameters to control the learning process \n",
    "    def initializehyperparm(self, sample_frames=30, batch_size=20, no_of_epochs=20):\n",
    "        self.sample_frames = sample_frames  # The attribute sample_frames defines the seq of images required to produce video data\n",
    "        self.batch_size = batch_size  # The attribute defines batch size that should be provided during the training of the model\n",
    "        self.no_of_epochs = no_of_epochs  # The no of iterations or the no of times the entire data is passed through NN for training\n",
    "        \n",
    "        \n",
    "        \n",
    "# Lets define a method that generates data for training of NN\n",
    "    def generator(self, source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0, self.total_frames-1, self.sample_frames)).astype(int)\n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        while True:\n",
    "            shuffled_data = np.random.permutation(folder_list)\n",
    "            total_batches = len(shuffled_data) // batch_size\n",
    "            for batch in range(total_batches):\n",
    "                batch_data, batch_label = self.one_batch_data(source_path, shuffled_data, \n",
    "                                                        batch_size, batch,\n",
    "                                                        img_idx, augment)\n",
    "                yield batch_data, batch_label\n",
    "                \n",
    "                \n",
    "            remaining_batches = len(shuffled_data) % batch_size\n",
    "            if remaining_batches != 0:\n",
    "                batch_data, batch_label = self.one_batch_data(source_path, shuffled_data,   \n",
    "                                                          total_batches, batch_size, img_idx, augment, remaining_batches)\n",
    "                yield batch_data, batch_label\n",
    "            \n",
    "            \n",
    "            \n",
    "# Lets generate the data for one batch\n",
    "    def one_batch_data(self, source_path, shuffled_data, batch, batch_size, img_idx, augment, remaining_batches=0):\n",
    "        seq_len = remaining_batches if remaining_batches else self.batch_size\n",
    "        batch_data = np.zeros((seq_len, len(img_idx), self.img_height, self.img_width, self.channels))\n",
    "        batch_label = np.zeros((seq_len, self.classes))\n",
    "\n",
    "        if (augment):\n",
    "            batch_data_aug = np.zeros((seq_len, len(img_idx), self.img_height, self.img_width, self.channels))\n",
    "\n",
    "        for folder in range(seq_len):\n",
    "            \n",
    "            imgs = os.listdir(source_path + '/' + shuffled_data[folder + (batch*batch_size)].split(';')[0])\n",
    "            \n",
    "            for idx, item in enumerate(img_idx):\n",
    "                    \n",
    "                img_read = imread(source_path + '/' + shuffled_data[folder + (batch*batch_size)].strip().split(';')[0]\n",
    "                                         + '/' + imgs[item]).astype(np.float32)\n",
    "                img_resize = resize(img_read, (self.img_height, self.img_width, 3))\n",
    "\n",
    "                batch_data[folder, idx, :, :, 0] = (img_resize[:, :, 0]) / 255\n",
    "                batch_data[folder, idx, :, :, 1] = (img_resize[:, :, 1]) / 255\n",
    "                batch_data[folder, idx, :, :, 2] = (img_resize[:, :, 2]) / 255\n",
    "\n",
    "                if (augment):\n",
    "                    transformed_img = cv2.warpAffine(img_read, np.float32([[1, 0, np.random.randint(-30, 30)],\n",
    "                                                                          [0, 1, np.random.randint(-30, 30)]]),\n",
    "                                                    (img_read.shape[1], img_read.shape[0]))\n",
    "                    gray_scale = cv2.cvtColor(transformed_img, cv2.COLOR_BGR2GRAY)\n",
    "                    x0, y0 = np.argwhere(gray_scale > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray_scale > 0).max(axis=0)\n",
    "                    cropped_img = transformed_img[x0:x1, y0:y1, :]\n",
    "                    img_resize = resize(cropped_img, (self.img_height, self.img_width, 3))\n",
    "                    \n",
    "                    matrix = cv2.getRotationMatrix2D((self.img_width//2, self.img_height//2), np.random.randint(-10,10), 1.0)\n",
    "                    rotated = cv2.warpAffine(img_resize, matrix, (self.img_width, self.img_height))\n",
    "\n",
    "                    batch_data_aug[folder, idx, :, :, 0] = (rotated[:, :, 0]) / 255\n",
    "                    batch_data_aug[folder, idx, :, :, 1] = (rotated[:, :, 1]) / 255\n",
    "                    batch_data_aug[folder, idx, :, :, 2] = (rotated[:, :, 2]) / 255\n",
    "                    \n",
    "                               \n",
    "            batch_label[folder, int(shuffled_data[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "    \n",
    "        if (augment):\n",
    "            batch_data = np.concatenate([batch_data, batch_data_aug])\n",
    "            batch_label = np.concatenate([batch_label, batch_label])\n",
    "\n",
    "        return batch_data, batch_label                                            \n",
    "                                                  \n",
    "        \n",
    "        \n",
    "# Lets define a method that trains NN using generator to load and augment data\n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_data_generator = self.generator(self.train_path, self.train_doc, augment=augment_data)                                            \n",
    "        val_data_generator = self.generator(self.val_path, self.val_doc)         \n",
    "         \n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ', '').replace(':', '_') + '/'                                         \n",
    "                                                     \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)                                      \n",
    "                                                     \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'                                            \n",
    "                                                     \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False,\n",
    "                                     mode='auto')                                            \n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=4, factor=0.2)                                            \n",
    "                                                   \n",
    "        callback_list = [checkpoint, LR]\n",
    "                                                     \n",
    "        if (self.num_train_seq % self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_seq / self.batch_size)                                      \n",
    "        else:                                     \n",
    "            steps_per_epoch = (self.num_train_seq // self.batch_size) + 1                                      \n",
    "                                                     \n",
    "        if (self.num_val_seq % self.batch_size) == 0:\n",
    "            val_steps = int(self.num_val_seq / self.batch_size)                                      \n",
    "        else:                                     \n",
    "            val_steps = (self.num_val_seq // self.batch_size) + 1                                            \n",
    "                                                     \n",
    "        history = model.fit_generator(train_data_generator, steps_per_epoch=steps_per_epoch, epochs=self.no_of_epochs, verbose=1, \n",
    "                            callbacks=callback_list, validation_data=val_data_generator, \n",
    "                            validation_steps=val_steps, class_weight=None, workers=1, initial_epoch=0)                                            \n",
    "                                                     \n",
    "        return history                                            \n",
    "                                                     \n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass                                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "694edfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 9 architecture with data augmentation\n",
    "class Conv3DModel9(ModelBuilderMoreAugmentation):\n",
    "    def define_model(self, filter_size=(3,3,3), dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "35a8132a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_520 (Conv3D)         (None, 20, 160, 160, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_520 (Activation  (None, 20, 160, 160, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_807 (B  (None, 20, 160, 160, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_416 (MaxPool  (None, 10, 80, 80, 16)    0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_521 (Conv3D)         (None, 10, 80, 80, 32)    13856     \n",
      "                                                                 \n",
      " activation_521 (Activation  (None, 10, 80, 80, 32)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_808 (B  (None, 10, 80, 80, 32)    128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_417 (MaxPool  (None, 5, 40, 40, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_522 (Conv3D)         (None, 5, 40, 40, 64)     55360     \n",
      "                                                                 \n",
      " activation_522 (Activation  (None, 5, 40, 40, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_809 (B  (None, 5, 40, 40, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_418 (MaxPool  (None, 2, 20, 20, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_523 (Conv3D)         (None, 2, 20, 20, 128)    221312    \n",
      "                                                                 \n",
      " activation_523 (Activation  (None, 2, 20, 20, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_810 (B  (None, 2, 20, 20, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_419 (MaxPool  (None, 1, 10, 10, 128)    0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_121 (Flatten)       (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_346 (Dense)           (None, 256)               3277056   \n",
      "                                                                 \n",
      " batch_normalization_811 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_294 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_347 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_812 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_295 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_348 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3638981 (13.88 MB)\n",
      "Trainable params: 3637477 (13.88 MB)\n",
      "Non-trainable params: 1504 (5.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 9 with different parameters\n",
    "Conv_model8 = Conv3DModel9()\n",
    "Conv_model8.initializepath(project_folder)\n",
    "Conv_model8.initialize_img_prop(img_width = 160, img_height = 160)\n",
    "Conv_model8.initializehyperparm(sample_frames = 20, batch_size = 20, no_of_epochs = 20) \n",
    "Conv_model9 = Conv_model8.define_model(dens_nuerons=256, dropout=0.5)\n",
    "Conv_model9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "5fbf4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model9.count_params()}')\n",
    "# model9_hist = Conv_model8.train_model(Conv_model9, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad3485f",
   "metadata": {},
   "source": [
    "# Model 10: Image Resolution: (120,120), Sample Frames: 16, Batch Size: 30, No of Epochs: 25 (Data Augmentation)\n",
    "## Similar to model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "c3d8da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 10 architecture with data augmentation\n",
    "class Conv3DModel9(ModelBuilderMoreAugmentation):\n",
    "    def define_model(self, filter_size=(3,3,3), dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "1f029f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_122\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_524 (Conv3D)         (None, 16, 120, 120, 16   400       \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_524 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_813 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_420 (MaxPool  (None, 8, 60, 60, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_525 (Conv3D)         (None, 8, 60, 60, 32)     4128      \n",
      "                                                                 \n",
      " activation_525 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_814 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_421 (MaxPool  (None, 4, 30, 30, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_526 (Conv3D)         (None, 4, 30, 30, 64)     16448     \n",
      "                                                                 \n",
      " activation_526 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_815 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_422 (MaxPool  (None, 2, 15, 15, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_527 (Conv3D)         (None, 2, 15, 15, 128)    65664     \n",
      "                                                                 \n",
      " activation_527 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_816 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_423 (MaxPool  (None, 1, 7, 7, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_122 (Flatten)       (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_349 (Dense)           (None, 256)               1605888   \n",
      "                                                                 \n",
      " batch_normalization_817 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_296 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_350 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_818 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_297 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_351 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1762613 (6.72 MB)\n",
      "Trainable params: 1761109 (6.72 MB)\n",
      "Non-trainable params: 1504 (5.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 10 with different parameters\n",
    "Conv_model9 = Conv3DModel9()\n",
    "Conv_model9.initializepath(project_folder)\n",
    "Conv_model9.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model9.initializehyperparm(sample_frames = 16, batch_size = 30, no_of_epochs = 25) \n",
    "Conv_model10 = Conv_model9.define_model(filter_size=(2,2,2), dens_nuerons=256, dropout=0.5)\n",
    "Conv_model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "88e8d883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model10.count_params()}')\n",
    "# model10_hist = Conv_model9.train_model(Conv_model10, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c3138",
   "metadata": {},
   "source": [
    "# Model 11: Image Resolution: (120,120), Sample Frames: 16, Batch Size: 20, No of Epochs: 25 (Data Augmentation)\n",
    "## Similar to model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "501ccb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 11 architecture with adding more layers\n",
    "class Conv3DModel9(ModelBuilderMoreAugmentation):\n",
    "    def define_model(self, filter_size=(3,3,3), dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())             # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "ac145fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_123\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_528 (Conv3D)         (None, 16, 120, 120, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_528 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_819 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " conv3d_529 (Conv3D)         (None, 16, 120, 120, 16   6928      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_529 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_820 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_424 (MaxPool  (None, 8, 60, 60, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_530 (Conv3D)         (None, 8, 60, 60, 32)     13856     \n",
      "                                                                 \n",
      " activation_530 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_821 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_531 (Conv3D)         (None, 8, 60, 60, 32)     27680     \n",
      "                                                                 \n",
      " activation_531 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_822 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_425 (MaxPool  (None, 4, 30, 30, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_532 (Conv3D)         (None, 4, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_532 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_823 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_533 (Conv3D)         (None, 4, 30, 30, 64)     110656    \n",
      "                                                                 \n",
      " activation_533 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_824 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_426 (MaxPool  (None, 2, 15, 15, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_534 (Conv3D)         (None, 2, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_534 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_825 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_535 (Conv3D)         (None, 2, 15, 15, 128)    442496    \n",
      "                                                                 \n",
      " activation_535 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_826 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_427 (MaxPool  (None, 1, 7, 7, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_123 (Flatten)       (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_352 (Dense)           (None, 256)               1605888   \n",
      "                                                                 \n",
      " batch_normalization_827 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_298 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_353 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_828 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_299 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_354 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2556533 (9.75 MB)\n",
      "Trainable params: 2554549 (9.74 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 11 with different parameters\n",
    "Conv_model10 = Conv3DModel9()\n",
    "Conv_model10.initializepath(project_folder)\n",
    "Conv_model10.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model10.initializehyperparm(sample_frames = 16, batch_size = 20, no_of_epochs = 25) \n",
    "Conv_model11 = Conv_model10.define_model(filter_size=(3,3,3), dens_nuerons=256, dropout=0.5)\n",
    "Conv_model11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "34628c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model11.count_params()}')\n",
    "# model11_hist = Conv_model10.train_model(Conv_model11, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff7d6d",
   "metadata": {},
   "source": [
    "# Model 12: Image Resolution: (120,120), Sample Frames: 16, Batch Size: 20, No of Epochs: 25 (Data Augmentation)\n",
    "## Similar to model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "e8590e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 12 architecture with adding dropout layers\n",
    "class Conv3DModel9(ModelBuilderMoreAugmentation):\n",
    "    def define_model(self, filter_size=(3,3,3), dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())             # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(16,filter_size, padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        model.add(Dropout(dropout))                  # Dropout Layer\n",
    "    \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(32,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        model.add(Dropout(dropout))                  # Dropout Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        model.add(Dropout(dropout))                  # Dropout Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())              # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,filter_size, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        model.add(Dropout(dropout))                  # Dropout Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "8c9a4831",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_124\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_536 (Conv3D)         (None, 16, 120, 120, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_536 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_829 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " conv3d_537 (Conv3D)         (None, 16, 120, 120, 16   6928      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_537 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_830 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_428 (MaxPool  (None, 8, 60, 60, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " dropout_300 (Dropout)       (None, 8, 60, 60, 16)     0         \n",
      "                                                                 \n",
      " conv3d_538 (Conv3D)         (None, 8, 60, 60, 32)     13856     \n",
      "                                                                 \n",
      " activation_538 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_831 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_539 (Conv3D)         (None, 8, 60, 60, 32)     27680     \n",
      "                                                                 \n",
      " activation_539 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_832 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_429 (MaxPool  (None, 4, 30, 30, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " dropout_301 (Dropout)       (None, 4, 30, 30, 32)     0         \n",
      "                                                                 \n",
      " conv3d_540 (Conv3D)         (None, 4, 30, 30, 64)     55360     \n",
      "                                                                 \n",
      " activation_540 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_833 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_541 (Conv3D)         (None, 4, 30, 30, 64)     110656    \n",
      "                                                                 \n",
      " activation_541 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_834 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_430 (MaxPool  (None, 2, 15, 15, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " dropout_302 (Dropout)       (None, 2, 15, 15, 64)     0         \n",
      "                                                                 \n",
      " conv3d_542 (Conv3D)         (None, 2, 15, 15, 128)    221312    \n",
      "                                                                 \n",
      " activation_542 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_835 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv3d_543 (Conv3D)         (None, 2, 15, 15, 128)    442496    \n",
      "                                                                 \n",
      " activation_543 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_836 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_431 (MaxPool  (None, 1, 7, 7, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " dropout_303 (Dropout)       (None, 1, 7, 7, 128)      0         \n",
      "                                                                 \n",
      " flatten_124 (Flatten)       (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_355 (Dense)           (None, 256)               1605888   \n",
      "                                                                 \n",
      " batch_normalization_837 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_304 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_356 (Dense)           (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_838 (B  (None, 256)               1024      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_305 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_357 (Dense)           (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2556533 (9.75 MB)\n",
      "Trainable params: 2554549 (9.74 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 12 with different parameters\n",
    "Conv_model11 = Conv3DModel9()\n",
    "Conv_model11.initializepath(project_folder)\n",
    "Conv_model11.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model11.initializehyperparm(sample_frames = 16, batch_size = 20, no_of_epochs = 25) \n",
    "Conv_model12 = Conv_model11.define_model(filter_size=(3,3,3), dens_nuerons=256, dropout=0.25)\n",
    "Conv_model12.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "4e1b477a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model12.count_params()}')\n",
    "# model12_hist = Conv_model11.train_model(Conv_model12, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68061005",
   "metadata": {},
   "source": [
    "# Model 13: Image Resolution: (100,100), Sample Frames: 16, Batch Size: 20, No of Epochs: 25 (Data Augmentation)\n",
    "## Similar to model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "0c3dd88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 13 architecture with reduced filter size\n",
    "class Conv3DModel9(ModelBuilderMoreAugmentation):\n",
    "    def define_model(self, dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,(3,3,3), padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "9834d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_125\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_544 (Conv3D)         (None, 16, 100, 100, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_544 (Activation  (None, 16, 100, 100, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_839 (B  (None, 16, 100, 100, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_432 (MaxPool  (None, 8, 50, 50, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_545 (Conv3D)         (None, 8, 50, 50, 32)     4128      \n",
      "                                                                 \n",
      " activation_545 (Activation  (None, 8, 50, 50, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_840 (B  (None, 8, 50, 50, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_433 (MaxPool  (None, 4, 25, 25, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_546 (Conv3D)         (None, 4, 25, 25, 64)     16448     \n",
      "                                                                 \n",
      " activation_546 (Activation  (None, 4, 25, 25, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_841 (B  (None, 4, 25, 25, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_434 (MaxPool  (None, 2, 12, 12, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_547 (Conv3D)         (None, 2, 12, 12, 128)    65664     \n",
      "                                                                 \n",
      " activation_547 (Activation  (None, 2, 12, 12, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_842 (B  (None, 2, 12, 12, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_435 (MaxPool  (None, 1, 6, 6, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_125 (Flatten)       (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_358 (Dense)           (None, 128)               589952    \n",
      "                                                                 \n",
      " batch_normalization_843 (B  (None, 128)               512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_306 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_359 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_844 (B  (None, 128)               512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_307 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_360 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 696645 (2.66 MB)\n",
      "Trainable params: 695653 (2.65 MB)\n",
      "Non-trainable params: 992 (3.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 13 with different parameters\n",
    "Conv_model12 = Conv3DModel9()\n",
    "Conv_model12.initializepath(project_folder)\n",
    "Conv_model12.initialize_img_prop(img_width = 100, img_height = 100)\n",
    "Conv_model12.initializehyperparm(sample_frames = 16, batch_size = 20, no_of_epochs = 25) \n",
    "Conv_model13 = Conv_model12.define_model(dens_nuerons=128, dropout=0.25)\n",
    "Conv_model13.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "72fed2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model13.count_params()}')\n",
    "# model13_hist = Conv_model12.train_model(Conv_model13, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f68c47",
   "metadata": {},
   "source": [
    "# Model 14: Image Resolution: (100,100), Sample Frames: 16, Batch Size: 20, No of Epochs: 25 (Data Augmentation)\n",
    "## Similar to model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "93436316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 14 architecture with reduced filter size\n",
    "class Conv3DModel9(ModelBuilderMoreAugmentation):\n",
    "    def define_model(self, dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16,(3,3,3), padding='same', \n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "    \n",
    "        model.add(Conv3D(32,(3,3,3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(64,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        model.add(Conv3D(128,(2,2,2), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(Flatten())  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))  # Hidden Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "d0fd6c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_548 (Conv3D)         (None, 16, 120, 120, 16   1312      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_548 (Activation  (None, 16, 120, 120, 16   0         \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " batch_normalization_845 (B  (None, 16, 120, 120, 16   64        \n",
      " atchNormalization)          )                                   \n",
      "                                                                 \n",
      " max_pooling3d_436 (MaxPool  (None, 8, 60, 60, 16)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_549 (Conv3D)         (None, 8, 60, 60, 32)     13856     \n",
      "                                                                 \n",
      " activation_549 (Activation  (None, 8, 60, 60, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_846 (B  (None, 8, 60, 60, 32)     128       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_437 (MaxPool  (None, 4, 30, 30, 32)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_550 (Conv3D)         (None, 4, 30, 30, 64)     16448     \n",
      "                                                                 \n",
      " activation_550 (Activation  (None, 4, 30, 30, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_847 (B  (None, 4, 30, 30, 64)     256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_438 (MaxPool  (None, 2, 15, 15, 64)     0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " conv3d_551 (Conv3D)         (None, 2, 15, 15, 128)    65664     \n",
      "                                                                 \n",
      " activation_551 (Activation  (None, 2, 15, 15, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_848 (B  (None, 2, 15, 15, 128)    512       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " max_pooling3d_439 (MaxPool  (None, 1, 7, 7, 128)      0         \n",
      " ing3D)                                                          \n",
      "                                                                 \n",
      " flatten_126 (Flatten)       (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_361 (Dense)           (None, 64)                401472    \n",
      "                                                                 \n",
      " batch_normalization_849 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_308 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_362 (Dense)           (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_850 (B  (None, 64)                256       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_309 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_363 (Dense)           (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504709 (1.93 MB)\n",
      "Trainable params: 503973 (1.92 MB)\n",
      "Non-trainable params: 736 (2.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 14 with different parameters\n",
    "Conv_model13 = Conv3DModel9()\n",
    "Conv_model13.initializepath(project_folder)\n",
    "Conv_model13.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model13.initializehyperparm(sample_frames = 16, batch_size = 20, no_of_epochs = 25) \n",
    "Conv_model14 = Conv_model13.define_model(dens_nuerons=64, dropout=0.25)\n",
    "Conv_model14.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "6a86e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model14.count_params()}')\n",
    "# model14_hist = Conv_model13.train_model(Conv_model14, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750c8201",
   "metadata": {},
   "source": [
    "# Model 15: Image Resolution: (120,120), Sample Frames: 18, Batch Size: 20, No of Epochs: 20 (Data Augmentation)\n",
    "## Similar to model 8 CNN+GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "d7a1313b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 15 architecture with CNN+GRU\n",
    "class CNNLSTM15(ModelBuilderMoreAugmentation):\n",
    "    def define_model(self, lstm_cells=64, dens_nuerons=64, dropout=0.25):\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv2D(16,(3,3), padding='same', activation='relu',\n",
    "                         input_shape = (self.sample_frames, self.img_height, self.img_width, self.channels))))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2)))) # Convolutional Layer\n",
    "    \n",
    "        model.add(TimeDistributed(Conv2D(32,(3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2)))) # Convolutional Layer\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(64,(3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2)))) # Convolutional Layer\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(128,(3,3), padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2)))) # Convolutional Layer\n",
    "        \n",
    "        \n",
    "        model.add(TimeDistributed(Flatten()))  # Input Layer\n",
    "        \n",
    "        \n",
    "        model.add(GRU(lstm_cells))\n",
    "        model.add(Dropout(dropout))  # LSTM Layer\n",
    "        \n",
    "        model.add(Dense(dens_nuerons, activation='relu'))\n",
    "        model.add(Dropout(dropout)) # Hidden Layer\n",
    "        \n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax')) # Output Layer\n",
    "        \n",
    "        optimiser = optimizers.Adam(learning_rate=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "a9efc849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_224 (Time  (None, 18, 120, 120, 16   448       \n",
      " Distributed)                )                                   \n",
      "                                                                 \n",
      " time_distributed_225 (Time  (None, 18, 120, 120, 16   64        \n",
      " Distributed)                )                                   \n",
      "                                                                 \n",
      " time_distributed_226 (Time  (None, 18, 60, 60, 16)    0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_227 (Time  (None, 18, 60, 60, 32)    4640      \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_228 (Time  (None, 18, 60, 60, 32)    128       \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_229 (Time  (None, 18, 30, 30, 32)    0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_230 (Time  (None, 18, 30, 30, 64)    18496     \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_231 (Time  (None, 18, 30, 30, 64)    256       \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_232 (Time  (None, 18, 15, 15, 64)    0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_233 (Time  (None, 18, 15, 15, 128)   73856     \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_234 (Time  (None, 18, 15, 15, 128)   512       \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_235 (Time  (None, 18, 7, 7, 128)     0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_236 (Time  (None, 18, 6272)          0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 128)               2458368   \n",
      "                                                                 \n",
      " dropout_310 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_364 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_311 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_365 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2573925 (9.82 MB)\n",
      "Trainable params: 2573445 (9.82 MB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 8 with different parameters\n",
    "Conv_model14 = CNNLSTM15()\n",
    "Conv_model14.initializepath(project_folder)\n",
    "Conv_model14.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model14.initializehyperparm(sample_frames = 18, batch_size = 20, no_of_epochs = 20) \n",
    "Conv_model15 = Conv_model14.define_model(lstm_cells=128, dens_nuerons=128, dropout=0.25)\n",
    "Conv_model15.build((None, 18, 120, 120, 3))\n",
    "Conv_model15.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "b7359f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model15.count_params()}')\n",
    "# model15_hist = Conv_model14.train_model(Conv_model15, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f8b208",
   "metadata": {},
   "source": [
    "### There is not much improvement in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30554bd2",
   "metadata": {},
   "source": [
    "# Model 16: Image Resolution: (120,120), Sample Frames: 16, Batch Size: 5, No of Epochs: 20 (Data Augmentation)\n",
    "### CNN+LSTM model -> MobileNet model\n",
    "### Lets import mobilenet model for speeding up the training process and improving performance. MobileNet model is a deep NN architecture designed for mobile and edge devices with limited computational resources. It is light weight and efficient making it suitable for real time appications on devices with constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "f7733e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "# Importing mobilenet model and creating instance\n",
    "from keras.applications import mobilenet\n",
    "mobilenet_transfer = mobilenet.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "class CNNLSTM_TL(ModelBuilderMoreAugmentation):     # Transfer Learning\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        \n",
    "        \n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False    # We are not training the mobilenet model weights\n",
    "        \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(LSTM(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f924b0",
   "metadata": {},
   "source": [
    "### The instance of mobilenet model pretrained on imagenet dataset is created. The pretrained weights of imagenet dataset are used as input. The top layer (fully connected layer) of mobilenet model which is responsible for image classification is excluded. This allows the mobilenet model to use as feature extractor. The mobilenet model is added as time distributed layer making it capable of processing sequence of images. The each layer of mobilenet model is frozen to retain the previous weights and to avoid the further training. This architecture combines the power of mobilenet model for feature extraction and sequential processing capability of LSTM for video classification task. The final dense layer is responsible for classifying input sequences into different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "b6687e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_128\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_237 (Time  (None, 16, 3, 3, 1024)    3228864   \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_238 (Time  (None, 16, 3, 3, 1024)    4096      \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_239 (Time  (None, 16, 1, 1, 1024)    0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_240 (Time  (None, 16, 1024)          0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 128)               590336    \n",
      "                                                                 \n",
      " dropout_312 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_366 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_313 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_367 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3840453 (14.65 MB)\n",
      "Trainable params: 609541 (2.33 MB)\n",
      "Non-trainable params: 3230912 (12.32 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 16 with different parameters\n",
    "Conv_model15 = CNNLSTM_TL()\n",
    "Conv_model15.initializepath(project_folder)\n",
    "Conv_model15.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model15.initializehyperparm(sample_frames = 16, batch_size = 5, no_of_epochs = 20) \n",
    "Conv_model16 = Conv_model15.define_model(lstm_cells=128, dense_neurons=128, dropout=0.25)\n",
    "Conv_model16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "07d62e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "# print(f'Total Param: {Conv_model16.count_params()}')\n",
    "# model16_hist = Conv_model15.train_model(Conv_model16, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86eaaa87",
   "metadata": {},
   "source": [
    "# Model 17: Image Resolution: (120,120), Sample Frames: 16, Batch Size: 5, No of Epochs: 20 (Data Augmentation)\n",
    "### CNN+GRU model -> MobileNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "4735563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build model 17 architecture with CNN+GRU\n",
    "class CNNGRU_TL(ModelBuilderMoreAugmentation):     # Transfer Learning\n",
    "    \n",
    "    def define_model(self,lstm_cells=64,dense_neurons=64,dropout=0.25):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(mobilenet_transfer,input_shape=(self.sample_frames, self.img_height, self.img_width, self.channels)))\n",
    "        \n",
    "          # We are training the mobilenet model weights\n",
    "        \n",
    "        \n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(GRU(lstm_cells))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(self.classes, activation='softmax'))\n",
    "        \n",
    "        \n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "e65bc2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_129\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_241 (Time  (None, 16, 3, 3, 1024)    3228864   \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_242 (Time  (None, 16, 3, 3, 1024)    4096      \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_243 (Time  (None, 16, 1, 1, 1024)    0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " time_distributed_244 (Time  (None, 16, 1024)          0         \n",
      " Distributed)                                                    \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 128)               443136    \n",
      "                                                                 \n",
      " dropout_314 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_368 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_315 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_369 (Dense)           (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3693253 (14.09 MB)\n",
      "Trainable params: 462341 (1.76 MB)\n",
      "Non-trainable params: 3230912 (12.32 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up the model 17 with different parameters\n",
    "Conv_model16 = CNNGRU_TL()\n",
    "Conv_model16.initializepath(project_folder)\n",
    "Conv_model16.initialize_img_prop(img_width = 120, img_height = 120)\n",
    "Conv_model16.initializehyperparm(sample_frames = 16, batch_size = 5, no_of_epochs = 20) \n",
    "Conv_model17 = Conv_model16.define_model(lstm_cells=128, dense_neurons=128, dropout=0.25)\n",
    "Conv_model17.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "9c809e35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Param: 3693253\n",
      "Epoch 1/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 1.2064 - categorical_accuracy: 0.5136\n",
      "Epoch 1: val_loss improved from inf to 0.68646, saving model to model_init_2024-01-0318_06_46.290805\\model-00001-1.20639-0.51357-0.68646-0.77000.h5\n",
      "133/133 [==============================] - 383s 3s/step - loss: 1.2064 - categorical_accuracy: 0.5136 - val_loss: 0.6865 - val_categorical_accuracy: 0.7700 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.6093 - categorical_accuracy: 0.7783\n",
      "Epoch 2: val_loss improved from 0.68646 to 0.62445, saving model to model_init_2024-01-0318_06_46.290805\\model-00002-0.60933-0.77828-0.62445-0.77000.h5\n",
      "133/133 [==============================] - 351s 3s/step - loss: 0.6093 - categorical_accuracy: 0.7783 - val_loss: 0.6245 - val_categorical_accuracy: 0.7700 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.4464 - categorical_accuracy: 0.8386\n",
      "Epoch 3: val_loss improved from 0.62445 to 0.47235, saving model to model_init_2024-01-0318_06_46.290805\\model-00003-0.44644-0.83861-0.47235-0.83000.h5\n",
      "133/133 [==============================] - 286s 2s/step - loss: 0.4464 - categorical_accuracy: 0.8386 - val_loss: 0.4724 - val_categorical_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.2553 - categorical_accuracy: 0.9223\n",
      "Epoch 4: val_loss did not improve from 0.47235\n",
      "133/133 [==============================] - 274s 2s/step - loss: 0.2553 - categorical_accuracy: 0.9223 - val_loss: 0.6655 - val_categorical_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.2692 - categorical_accuracy: 0.9057\n",
      "Epoch 5: val_loss improved from 0.47235 to 0.40367, saving model to model_init_2024-01-0318_06_46.290805\\model-00005-0.26917-0.90573-0.40367-0.86000.h5\n",
      "133/133 [==============================] - 264s 2s/step - loss: 0.2692 - categorical_accuracy: 0.9057 - val_loss: 0.4037 - val_categorical_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.1701 - categorical_accuracy: 0.9434\n",
      "Epoch 6: val_loss did not improve from 0.40367\n",
      "133/133 [==============================] - 271s 2s/step - loss: 0.1701 - categorical_accuracy: 0.9434 - val_loss: 0.4131 - val_categorical_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.1223 - categorical_accuracy: 0.9593\n",
      "Epoch 7: val_loss improved from 0.40367 to 0.27655, saving model to model_init_2024-01-0318_06_46.290805\\model-00007-0.12225-0.95928-0.27655-0.88000.h5\n",
      "133/133 [==============================] - 267s 2s/step - loss: 0.1223 - categorical_accuracy: 0.9593 - val_loss: 0.2766 - val_categorical_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.1508 - categorical_accuracy: 0.9510\n",
      "Epoch 8: val_loss did not improve from 0.27655\n",
      "133/133 [==============================] - 273s 2s/step - loss: 0.1508 - categorical_accuracy: 0.9510 - val_loss: 0.5048 - val_categorical_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.1333 - categorical_accuracy: 0.9532\n",
      "Epoch 9: val_loss did not improve from 0.27655\n",
      "133/133 [==============================] - 270s 2s/step - loss: 0.1333 - categorical_accuracy: 0.9532 - val_loss: 0.4543 - val_categorical_accuracy: 0.8400 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.1518 - categorical_accuracy: 0.9457\n",
      "Epoch 10: val_loss improved from 0.27655 to 0.21622, saving model to model_init_2024-01-0318_06_46.290805\\model-00010-0.15182-0.94570-0.21622-0.90000.h5\n",
      "133/133 [==============================] - 276s 2s/step - loss: 0.1518 - categorical_accuracy: 0.9457 - val_loss: 0.2162 - val_categorical_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.1270 - categorical_accuracy: 0.9578\n",
      "Epoch 11: val_loss did not improve from 0.21622\n",
      "133/133 [==============================] - 285s 2s/step - loss: 0.1270 - categorical_accuracy: 0.9578 - val_loss: 0.2866 - val_categorical_accuracy: 0.8700 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0968 - categorical_accuracy: 0.9668\n",
      "Epoch 12: val_loss did not improve from 0.21622\n",
      "133/133 [==============================] - 269s 2s/step - loss: 0.0968 - categorical_accuracy: 0.9668 - val_loss: 0.5176 - val_categorical_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0791 - categorical_accuracy: 0.9713\n",
      "Epoch 13: val_loss did not improve from 0.21622\n",
      "133/133 [==============================] - 282s 2s/step - loss: 0.0791 - categorical_accuracy: 0.9713 - val_loss: 0.4466 - val_categorical_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0765 - categorical_accuracy: 0.9744\n",
      "Epoch 14: val_loss did not improve from 0.21622\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "133/133 [==============================] - 280s 2s/step - loss: 0.0765 - categorical_accuracy: 0.9744 - val_loss: 0.3551 - val_categorical_accuracy: 0.8300 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0637 - categorical_accuracy: 0.9842\n",
      "Epoch 15: val_loss did not improve from 0.21622\n",
      "133/133 [==============================] - 284s 2s/step - loss: 0.0637 - categorical_accuracy: 0.9842 - val_loss: 0.3919 - val_categorical_accuracy: 0.8500 - lr: 2.0000e-04\n",
      "Epoch 16/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0411 - categorical_accuracy: 0.9827\n",
      "Epoch 16: val_loss did not improve from 0.21622\n",
      "133/133 [==============================] - 282s 2s/step - loss: 0.0411 - categorical_accuracy: 0.9827 - val_loss: 0.4080 - val_categorical_accuracy: 0.8300 - lr: 2.0000e-04\n",
      "Epoch 17/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0524 - categorical_accuracy: 0.9819\n",
      "Epoch 17: val_loss did not improve from 0.21622\n",
      "133/133 [==============================] - 297s 2s/step - loss: 0.0524 - categorical_accuracy: 0.9819 - val_loss: 0.4411 - val_categorical_accuracy: 0.8600 - lr: 2.0000e-04\n",
      "Epoch 18/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0375 - categorical_accuracy: 0.9887\n",
      "Epoch 18: val_loss did not improve from 0.21622\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "133/133 [==============================] - 277s 2s/step - loss: 0.0375 - categorical_accuracy: 0.9887 - val_loss: 0.4627 - val_categorical_accuracy: 0.8400 - lr: 2.0000e-04\n",
      "Epoch 19/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0251 - categorical_accuracy: 0.9940\n",
      "Epoch 19: val_loss did not improve from 0.21622\n",
      "133/133 [==============================] - 266s 2s/step - loss: 0.0251 - categorical_accuracy: 0.9940 - val_loss: 0.3850 - val_categorical_accuracy: 0.8900 - lr: 4.0000e-05\n",
      "Epoch 20/20\n",
      "133/133 [==============================] - ETA: 0s - loss: 0.0302 - categorical_accuracy: 0.9894\n",
      "Epoch 20: val_loss did not improve from 0.21622\n",
      "133/133 [==============================] - 268s 2s/step - loss: 0.0302 - categorical_accuracy: 0.9894 - val_loss: 0.4213 - val_categorical_accuracy: 0.8600 - lr: 4.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Lets check the total parameters during training of model\n",
    "print(f'Total Param: {Conv_model17.count_params()}')\n",
    "model17_hist = Conv_model16.train_model(Conv_model17, augment_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc422a",
   "metadata": {},
   "source": [
    "### Experimenting with other combinations of hyperparameters like, activation functions (ReLU, tanh, sigmoid), other optimizers like Adagrad() and Adadelta()  can further help develop better and more accurate models. Experimenting with other combinations of hyperparameters like the filter size, paddings, stride_length, batch_normalization, dropouts etc. can further help improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4319772",
   "metadata": {},
   "source": [
    "# Model 8: Image Resolution: (120,120), Sample Frames: 18, Batch Size: 20, No of Epochs: 25\n",
    "# CNN + LSTM Mode\n",
    "# Gave Best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ce610e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
